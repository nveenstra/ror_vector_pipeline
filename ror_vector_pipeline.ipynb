{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382fabd0",
   "metadata": {},
   "source": [
    "# ROR â†’ Postgres + pgvector (multilingualâ€‘e5â€‘large)\n",
    "**Order:** 1) Imports & setup â†’ 2) Schema â†’ 3) Load & normalize â†’ 4) Core upsert â†’ 5) Child tables â†’ 6) index_text views â†’ 7) Embed (with progress bars) â†’ 8) ANN indexes â†’ 9) Search helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31743549",
   "metadata": {},
   "source": [
    "## 1) Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e716a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"psycopg[binary]>=3.1\" \"pgvector>=0.3.2\" sentence-transformers torch tqdm orjson zipfile36 ipywidgets\n",
    "\n",
    "import os, json, zipfile\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import orjson\n",
    "from tqdm.auto import tqdm\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# --- Database connection parameters ---\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = 5432\n",
    "DB_NAME = 'ror_db'\n",
    "DB_USER = 'username'\n",
    "DB_PASSWORD = 'password'\n",
    "\n",
    "DSN = f'postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}'\n",
    "\n",
    "# --- File paths and model settings ---\n",
    "ROR_ZIP_PATH = Path(os.environ.get('ROR_ZIP', 'ror-latest.zip')).expanduser()\n",
    "MODEL_NAME = 'intfloat/multilingual-e5-large'  # 1024â€‘dim\n",
    "DEVICE = 'mps' if getattr(torch.backends, 'mps', None) and torch.backends.mps.is_available() else 'cpu'\n",
    "EMBED_DIM = 1024\n",
    "\n",
    "print('Using DSN:', DSN)\n",
    "print('ROR dump exists:', ROR_ZIP_PATH.exists(), str(ROR_ZIP_PATH))\n",
    "print('Device:', DEVICE)\n",
    "\n",
    "# Lazy model loader + embedding helper\n",
    "_model = None\n",
    "def embed_texts(texts: Iterable[str], is_passage: bool = True, batch_size: int = 64) -> np.ndarray:\n",
    "    global _model\n",
    "    if _model is None:\n",
    "        _model = SentenceTransformer(MODEL_NAME, device=DEVICE)\n",
    "    prefix = 'passage: ' if is_passage else 'query: '\n",
    "    tagged = [prefix + (t or '') for t in texts]\n",
    "    vecs = _model.encode(tagged, batch_size=batch_size, normalize_embeddings=True, show_progress_bar=True)\n",
    "    return np.asarray(vecs, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d417482e",
   "metadata": {},
   "source": [
    "## 2) Create schema (pgvector + tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f06ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(DSN, autocommit=True) as conn:\n",
    "    register_vector(conn)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute('''\n",
    "CREATE EXTENSION IF NOT EXISTS vector;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org (\n",
    "  ror_id            text PRIMARY KEY,\n",
    "  status            text NOT NULL CHECK (status IN ('active','inactive','withdrawn')),\n",
    "  types             text[] NOT NULL,\n",
    "  established       integer,\n",
    "  created_date      date NOT NULL,\n",
    "  created_schema_version text NOT NULL,\n",
    "  last_modified_date date NOT NULL,\n",
    "  last_modified_schema_version text NOT NULL,\n",
    "  country_code      char(2),\n",
    "  search_text       text,\n",
    "  embedding         vector(1024)\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS ror_org_status_idx ON ror_org(status);\n",
    "CREATE INDEX IF NOT EXISTS ror_org_types_gin  ON ror_org USING GIN (types);\n",
    "CREATE INDEX IF NOT EXISTS ror_org_cc_idx     ON ror_org(country_code);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org_name (\n",
    "  id      bigserial PRIMARY KEY,\n",
    "  ror_id  text NOT NULL REFERENCES ror_org(ror_id) ON DELETE CASCADE,\n",
    "  value   text NOT NULL,\n",
    "  types   text[] NOT NULL,\n",
    "  lang    char(2)\n",
    ");\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ror_org_name_uq ON ror_org_name(ror_id, value, lang, types);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org_link (\n",
    "  id     bigserial PRIMARY KEY,\n",
    "  ror_id text NOT NULL REFERENCES ror_org(ror_id) ON DELETE CASCADE,\n",
    "  type   text NOT NULL,\n",
    "  value  text NOT NULL\n",
    ");\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ror_org_link_uq ON ror_org_link(ror_id, type, value);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org_external_id (\n",
    "  id        bigserial PRIMARY KEY,\n",
    "  ror_id    text NOT NULL REFERENCES ror_org(ror_id) ON DELETE CASCADE,\n",
    "  type      text NOT NULL,\n",
    "  all_ids   text[] NOT NULL,\n",
    "  preferred text\n",
    ");\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ror_org_extid_uq ON ror_org_external_id(ror_id, type);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org_location (\n",
    "  id        bigserial PRIMARY KEY,\n",
    "  ror_id    text NOT NULL REFERENCES ror_org(ror_id) ON DELETE CASCADE,\n",
    "  geonames_id integer NOT NULL,\n",
    "  name      text NOT NULL,\n",
    "  lat       double precision,\n",
    "  lng       double precision,\n",
    "  continent_code text,\n",
    "  continent_name text,\n",
    "  country_code char(2),\n",
    "  country_name text,\n",
    "  country_subdivision_code text,\n",
    "  country_subdivision_name text\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS ror_org_loc_country_idx ON ror_org_location(country_code);\n",
    "CREATE INDEX IF NOT EXISTS ror_org_loc_geonames_idx ON ror_org_location(geonames_id);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org_relationship (\n",
    "  id        bigserial PRIMARY KEY,\n",
    "  ror_id    text NOT NULL REFERENCES ror_org(ror_id) ON DELETE CASCADE,\n",
    "  rel_type  text NOT NULL,\n",
    "  target_id text NOT NULL,\n",
    "  label     text NOT NULL\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS ror_org_rel_src_idx ON ror_org_relationship(ror_id, rel_type);\n",
    "CREATE INDEX IF NOT EXISTS ror_org_rel_tgt_idx ON ror_org_relationship(target_id);\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS ror_org_domain (\n",
    "  id      bigserial PRIMARY KEY,\n",
    "  ror_id  text NOT NULL REFERENCES ror_org(ror_id) ON DELETE CASCADE,\n",
    "  domain  text NOT NULL\n",
    ");\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ror_org_domain_uq ON ror_org_domain(ror_id, domain);\n",
    "''')\n",
    "print('Schema ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530e3b4",
   "metadata": {},
   "source": [
    "## 3) Load & normalize ROR (v2 JSONâ€‘inâ€‘ZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb82637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_json_from_zip(zip_path: Path) -> str:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        cands = [n for n in zf.namelist() if n.endswith('.json') and ('v2' in n.lower() or '/v2/' in n)]\n",
    "        if not cands:\n",
    "            cands = [n for n in zf.namelist() if n.endswith('.json')]\n",
    "        if not cands:\n",
    "            raise RuntimeError('No JSON file found in the ROR dump zip.')\n",
    "        return max(cands, key=lambda n: zf.getinfo(n).file_size)\n",
    "\n",
    "def load_ror(zip_path: Path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        json_name = _pick_json_from_zip(zip_path)\n",
    "        with zf.open(json_name) as f:\n",
    "            return orjson.loads(f.read())\n",
    "\n",
    "def collect_name_variants(org: Dict[str, Any]) -> List[str]:\n",
    "    names = set()\n",
    "    if org.get('name'): names.add(org['name'])\n",
    "    for key in ('aliases','labels','acronyms'):\n",
    "        for v in org.get(key) or []:\n",
    "            if isinstance(v, dict):\n",
    "                val = v.get('label') or v.get('value') or v.get('name')\n",
    "                if val: names.add(val)\n",
    "            elif isinstance(v, str):\n",
    "                names.add(v)\n",
    "    return sorted({n.strip() for n in names if isinstance(n, str) and n.strip()})\n",
    "\n",
    "def normalize(org: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    rid = org.get('id') or org.get('ror_id') or ''\n",
    "    names = collect_name_variants(org)\n",
    "    cc = ((org.get('country') or {}).get('country_code')) or ''\n",
    "    primary = org.get('name') or (names[0] if names else '')\n",
    "    search_text = primary\n",
    "    if cc: search_text += f' (country:{cc})'\n",
    "    if len(names) > 1:\n",
    "        search_text += ' | aka: ' + '; '.join(names[1:][:10])\n",
    "    return {\n",
    "        'ror_id': rid,\n",
    "        'status': org.get('status') or 'active',\n",
    "        'types': org.get('types') or [],\n",
    "        'established': org.get('established'),\n",
    "        'created_date': ((org.get('admin') or {}).get('created') or {}).get('date') or '1970-01-01',\n",
    "        'created_schema_version': ((org.get('admin') or {}).get('created') or {}).get('schema_version') or '2.1',\n",
    "        'last_modified_date': ((org.get('admin') or {}).get('last_modified') or {}).get('date') or '1970-01-01',\n",
    "        'last_modified_schema_version': ((org.get('admin') or {}).get('last_modified') or {}).get('schema_version') or '2.1',\n",
    "        'country_code': cc or None,\n",
    "        'search_text': search_text,\n",
    "        'name': primary,\n",
    "        'names': names,\n",
    "        'links': org.get('links') or [],\n",
    "        'external_ids': org.get('external_ids') or [],\n",
    "        'locations': org.get('locations') or [],\n",
    "        'relationships': org.get('relationships') or [],\n",
    "        'domains': org.get('domains') or [],\n",
    "    }\n",
    "\n",
    "raw = load_ror(ROR_ZIP_PATH)\n",
    "rows = [normalize(o) for o in raw]\n",
    "print('Organizations:', len(rows))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b06a9",
   "metadata": {},
   "source": [
    "## 4) Upsert core orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4756a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_org = (\n",
    "    \"INSERT INTO ror_org (\"\n",
    "    \"  ror_id, status, types, established,\"\n",
    "    \"  created_date, created_schema_version,\"\n",
    "    \"  last_modified_date, last_modified_schema_version,\"\n",
    "    \"  country_code, search_text) \"\n",
    "    \"VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) \"\n",
    "    \"ON CONFLICT (ror_id) DO UPDATE SET \"\n",
    "    \"  status=EXCLUDED.status, types=EXCLUDED.types, established=EXCLUDED.established,\"\n",
    "    \"  created_date=EXCLUDED.created_date, created_schema_version=EXCLUDED.created_schema_version,\"\n",
    "    \"  last_modified_date=EXCLUDED.last_modified_date, last_modified_schema_version=EXCLUDED.last_modified_schema_version,\"\n",
    "    \"  country_code=EXCLUDED.country_code, search_text=EXCLUDED.search_text;\"\n",
    ")\n",
    "\n",
    "with psycopg.connect(DSN, autocommit=False) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        BATCH = 1000\n",
    "        for i in tqdm(range(0, len(rows), BATCH), desc='Upserting orgs'):\n",
    "            chunk = rows[i:i+BATCH]\n",
    "            cur.executemany(\n",
    "                ins_org,\n",
    "                [(\n",
    "                    r['ror_id'], r['status'], r['types'], r['established'],\n",
    "                    r['created_date'], r['created_schema_version'],\n",
    "                    r['last_modified_date'], r['last_modified_schema_version'],\n",
    "                    r['country_code'], r['search_text']\n",
    "                ) for r in chunk]\n",
    "            )\n",
    "    conn.commit()\n",
    "print('Core orgs upserted.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff768b3d",
   "metadata": {},
   "source": [
    "## 5) Upsert child tables (names, links, external_ids, locations, relationships, domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _nz(x):\n",
    "    return x.strip() if isinstance(x, str) else x\n",
    "\n",
    "def rows_names(r):\n",
    "    out = []\n",
    "    rid = r.get('ror_id')\n",
    "    if not rid:\n",
    "        return out\n",
    "    primary = _nz(r.get('name') or '')\n",
    "    if primary:\n",
    "        out.append((rid, primary, ['ror_display'], None))\n",
    "    for v in r.get('names') or []:\n",
    "        v = _nz(v)\n",
    "        if not v:\n",
    "            continue\n",
    "        typ = 'acronym' if (v.isupper() and len(v) <= 12) else 'alias'\n",
    "        out.append((rid, v, [typ], None))\n",
    "    return out\n",
    "\n",
    "def rows_links(r):\n",
    "    out = []\n",
    "    rid = r.get('ror_id')\n",
    "    if not rid:\n",
    "        return out\n",
    "    for lk in (r.get('links') or []):\n",
    "        t = _nz(lk.get('type') or 'website')\n",
    "        v = _nz(lk.get('value') or '')\n",
    "        if v:\n",
    "            out.append((rid, t, v))\n",
    "    return out\n",
    "\n",
    "def rows_extids(r):\n",
    "    out = []\n",
    "    rid = r.get('ror_id')\n",
    "    if not rid:\n",
    "        return out\n",
    "    for e in (r.get('external_ids') or []):\n",
    "        t = _nz(e.get('type') or '')\n",
    "        all_ids = e.get('all') or e.get('all_ids') or []\n",
    "        pref = _nz(e.get('preferred') or None)\n",
    "        if t and all_ids:\n",
    "            out.append((rid, t, [str(x) for x in all_ids], pref))\n",
    "    return out\n",
    "\n",
    "def rows_locations(r):\n",
    "    out = []\n",
    "    rid = r.get('ror_id')\n",
    "    if not rid:\n",
    "        return out\n",
    "    for loc in (r.get('locations') or []):\n",
    "        g = loc.get('geonames_id')\n",
    "        det = loc.get('geonames_details') or {}\n",
    "        name = _nz(det.get('name') or '')\n",
    "        if not g or not name:\n",
    "            continue\n",
    "        out.append((\n",
    "            rid, int(g), \n",
    "            _nz(det.get('name') or None),\n",
    "            _nz(det.get('lat') or None),\n",
    "            _nz(det.get('lng') or None),\n",
    "            _nz(det.get('continent_code') or None),\n",
    "            _nz(det.get('continent_name') or None),\n",
    "            _nz(det.get('country_code') or None),\n",
    "            _nz(det.get('country_name') or None),\n",
    "            _nz(det.get('country_subdivision_code') or None),\n",
    "            _nz(det.get('country_subdivision_name') or None),\n",
    "        ))\n",
    "    return out\n",
    "\n",
    "def rows_relationships(r):\n",
    "    out = []\n",
    "    rid = r.get('ror_id')\n",
    "    if not rid:\n",
    "        return out\n",
    "    for rel in (r.get('relationships') or []):\n",
    "        rt  = _nz(rel.get('type') or '')\n",
    "        tid = _nz(rel.get('id') or '')\n",
    "        lbl = _nz(rel.get('label') or '')\n",
    "        if rt and tid and lbl:\n",
    "            out.append((rid, rt, tid, lbl))\n",
    "    return out\n",
    "\n",
    "def rows_domains(r):\n",
    "    out = []\n",
    "    rid = r.get('ror_id')\n",
    "    if not rid:\n",
    "        return out\n",
    "    for d in (r.get('domains') or []):\n",
    "        d = _nz(d)\n",
    "        if d:\n",
    "            out.append((rid, d))\n",
    "    if not out:\n",
    "        for lk in (r.get('links') or []):\n",
    "            v = _nz(lk.get('value') or '')\n",
    "            try:\n",
    "                host = urlparse(v).hostname\n",
    "                if host:\n",
    "                    out.append((rid, host.lower()))\n",
    "            except Exception:\n",
    "                pass\n",
    "    seen, dedup = set(), []\n",
    "    for _, d in out:\n",
    "        if d not in seen:\n",
    "            seen.add(d)\n",
    "            dedup.append((rid, d))\n",
    "    return dedup\n",
    "\n",
    "ins_name = \"\"\"\n",
    "INSERT INTO ror_org_name (ror_id, value, types, lang)\n",
    "VALUES (%s,%s,%s,%s)\n",
    "ON CONFLICT (ror_id, value, lang, types) DO NOTHING;\n",
    "\"\"\"\n",
    "ins_link = \"\"\"\n",
    "INSERT INTO ror_org_link (ror_id, type, value)\n",
    "VALUES (%s,%s,%s)\n",
    "ON CONFLICT (ror_id, type, value) DO NOTHING;\n",
    "\"\"\"\n",
    "ins_extid = \"\"\"\n",
    "INSERT INTO ror_org_external_id (ror_id, type, all_ids, preferred)\n",
    "VALUES (%s,%s,%s,%s)\n",
    "ON CONFLICT (ror_id, type) DO UPDATE SET all_ids = EXCLUDED.all_ids, preferred = EXCLUDED.preferred;\n",
    "\"\"\"\n",
    "ins_loc = \"\"\"\n",
    "INSERT INTO ror_org_location (\n",
    "  ror_id, geonames_id, name, lat, lng,\n",
    "  continent_code, continent_name,\n",
    "  country_code, country_name,\n",
    "  country_subdivision_code, country_subdivision_name\n",
    ") VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "ON CONFLICT DO NOTHING;\n",
    "\"\"\"\n",
    "ins_rel = \"\"\"\n",
    "INSERT INTO ror_org_relationship (ror_id, rel_type, target_id, label)\n",
    "VALUES (%s,%s,%s,%s)\n",
    "ON CONFLICT DO NOTHING;\n",
    "\"\"\"\n",
    "ins_dom = \"\"\"\n",
    "INSERT INTO ror_org_domain (ror_id, domain)\n",
    "VALUES (%s,%s)\n",
    "ON CONFLICT (ror_id, domain) DO NOTHING;\n",
    "\"\"\"\n",
    "\n",
    "BATCH = 1000\n",
    "with psycopg.connect(DSN, autocommit=False) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # names\n",
    "        buf = []\n",
    "        for r in rows:\n",
    "            buf.extend(rows_names(r))\n",
    "            if len(buf) >= BATCH:\n",
    "                cur.executemany(ins_name, buf); buf.clear()\n",
    "        if buf:\n",
    "            cur.executemany(ins_name, buf); buf.clear()\n",
    "\n",
    "        # links\n",
    "        for r in rows:\n",
    "            vals = rows_links(r)\n",
    "            if vals:\n",
    "                cur.executemany(ins_link, vals)\n",
    "\n",
    "        # external IDs\n",
    "        buf = []\n",
    "        for r in rows:\n",
    "            buf.extend(rows_extids(r))\n",
    "            if len(buf) >= BATCH:\n",
    "                cur.executemany(ins_extid, buf); buf.clear()\n",
    "        if buf:\n",
    "            cur.executemany(ins_extid, buf); buf.clear()\n",
    "\n",
    "        # locations\n",
    "        buf = []\n",
    "        for r in rows:\n",
    "            buf.extend(rows_locations(r))\n",
    "            if len(buf) >= BATCH:\n",
    "                cur.executemany(ins_loc, buf); buf.clear()\n",
    "        if buf:\n",
    "            cur.executemany(ins_loc, buf); buf.clear()\n",
    "\n",
    "        # relationships\n",
    "        buf = []\n",
    "        for r in rows:\n",
    "            buf.extend(rows_relationships(r))\n",
    "            if len(buf) >= BATCH:\n",
    "                cur.executemany(ins_rel, buf); buf.clear()\n",
    "        if buf:\n",
    "            cur.executemany(ins_rel, buf); buf.clear()\n",
    "\n",
    "        # domains\n",
    "        buf = []\n",
    "        for r in rows:\n",
    "            buf.extend(rows_domains(r))\n",
    "            if len(buf) >= BATCH:\n",
    "                cur.executemany(ins_dom, buf); buf.clear()\n",
    "        if buf:\n",
    "            cur.executemany(ins_dom, buf); buf.clear()\n",
    "\n",
    "    conn.commit()\n",
    "print('Child tables loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd1c24f",
   "metadata": {},
   "source": [
    "## 6) Compose index_text from all tables (SQL views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe90609",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(DSN, autocommit=True) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute('''\n",
    "CREATE OR REPLACE VIEW ror_org_index_text AS\n",
    "SELECT\n",
    "  o.ror_id,\n",
    "  coalesce(\n",
    "    (SELECT n.value FROM ror_org_name n WHERE n.ror_id = o.ror_id AND 'ror_display' = ANY(n.types) ORDER BY n.id LIMIT 1),\n",
    "    (SELECT n.value FROM ror_org_name n WHERE n.ror_id = o.ror_id ORDER BY n.id LIMIT 1),\n",
    "    ''\n",
    "  ) AS display_name,\n",
    "  coalesce((\n",
    "    SELECT string_agg(n.value, '; ' ORDER BY n.id)\n",
    "    FROM ror_org_name n\n",
    "    WHERE n.ror_id = o.ror_id AND ('alias' = ANY(n.types) OR 'acronym' = ANY(n.types) OR 'label' = ANY(n.types))\n",
    "  ), '') AS aka_block,\n",
    "  coalesce((\n",
    "    SELECT string_agg(d.domain, '; ' ORDER BY d.domain)\n",
    "    FROM ror_org_domain d\n",
    "    WHERE d.ror_id = o.ror_id\n",
    "  ), '') AS domain_block,\n",
    "  coalesce((\n",
    "    SELECT string_agg(l.value, '; ' ORDER BY l.id)\n",
    "    FROM ror_org_link l\n",
    "    WHERE l.ror_id = o.ror_id\n",
    "  ), '') AS links_block,\n",
    "  coalesce((\n",
    "    SELECT string_agg(\n",
    "             concat(e.type, ':', coalesce(e.preferred,''),\n",
    "                    CASE WHEN e.preferred IS NOT NULL AND cardinality(e.all_ids) > 0 THEN '|' ELSE '' END,\n",
    "                    array_to_string(e.all_ids, ',')),\n",
    "             ' ; ' ORDER BY e.id)\n",
    "    FROM ror_org_external_id e\n",
    "    WHERE e.ror_id = o.ror_id\n",
    "  ), '') AS extid_block,\n",
    "  coalesce((\n",
    "    SELECT string_agg(\n",
    "             concat_ws(' ',\n",
    "               coalesce(l.name,''),\n",
    "               coalesce(l.country_subdivision_name,''),\n",
    "               coalesce(l.country_name,''),\n",
    "               CASE WHEN l.country_code IS NOT NULL THEN '(country:'||l.country_code||')' ELSE '' END\n",
    "             ), ' ; ' ORDER BY l.id)\n",
    "    FROM ror_org_location l\n",
    "    WHERE l.ror_id = o.ror_id\n",
    "  ), '') AS location_block,\n",
    "  coalesce((\n",
    "    SELECT string_agg(concat(r.rel_type, ': ', r.label), ' ; ' ORDER BY r.id)\n",
    "    FROM ror_org_relationship r\n",
    "    WHERE r.ror_id = o.ror_id\n",
    "  ), '') AS rel_block,\n",
    "  o.country_code\n",
    "FROM ror_org o;\n",
    "CREATE OR REPLACE VIEW ror_org_index_text_full AS\n",
    "SELECT\n",
    "  ror_id,\n",
    "  trim(both ' ' from\n",
    "    concat(\n",
    "      display_name,\n",
    "      CASE WHEN display_name <> '' AND country_code IS NOT NULL THEN ' (country:'||country_code||')' ELSE '' END,\n",
    "      CASE WHEN aka_block     <> '' THEN ' | aka: '     || aka_block     ELSE '' END,\n",
    "      CASE WHEN domain_block  <> '' THEN ' | domains: ' || domain_block  ELSE '' END,\n",
    "      CASE WHEN links_block   <> '' THEN ' | links: '   || links_block   ELSE '' END,\n",
    "      CASE WHEN extid_block   <> '' THEN ' | ids: '     || extid_block   ELSE '' END,\n",
    "      CASE WHEN location_block<> '' THEN ' | locs: '    || location_block ELSE '' END,\n",
    "      CASE WHEN rel_block     <> '' THEN ' | rel: '     || rel_block     ELSE '' END\n",
    "    )\n",
    "  ) AS index_text\n",
    "FROM ror_org_index_text;\n",
    "''')\n",
    "print('Views created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "\n",
    "with psycopg.connect(\"postgresql://nick:postgres@localhost:5432/ror_db\", autocommit=True) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "        CREATE INDEX IF NOT EXISTS ror_org_name_rid_idx        ON ror_org_name(ror_id);\n",
    "        CREATE INDEX IF NOT EXISTS ror_org_link_rid_idx        ON ror_org_link(ror_id);\n",
    "        CREATE INDEX IF NOT EXISTS ror_org_external_id_rid_idx ON ror_org_external_id(ror_id);\n",
    "        CREATE INDEX IF NOT EXISTS ror_org_location_rid_idx    ON ror_org_location(ror_id);\n",
    "        CREATE INDEX IF NOT EXISTS ror_org_relationship_rid_idx ON ror_org_relationship(ror_id);\n",
    "        CREATE INDEX IF NOT EXISTS ror_org_domain_rid_idx      ON ror_org_domain(ror_id);\n",
    "\n",
    "        ANALYZE ror_org;\n",
    "        ANALYZE ror_org_name;\n",
    "        ANALYZE ror_org_link;\n",
    "        ANALYZE ror_org_external_id;\n",
    "        ANALYZE ror_org_location;\n",
    "        ANALYZE ror_org_relationship;\n",
    "        ANALYZE ror_org_domain;\n",
    "        \"\"\")\n",
    "print(\"Indexes ensured and stats updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”Ž ROR DB dashboard (SQLAlchemy + Pandas) â€” counts + samples\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "#DB_HOST = \"localhost\"; DB_PORT = 5432\n",
    "#DB_NAME = \"ror_db\";   DB_USER = \"nick\"; DB_PASSWORD = \"postgres\"\n",
    "\n",
    "ENGINE_URL = f\"postgresql+psycopg://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(ENGINE_URL, future=True)\n",
    "\n",
    "TABLES = [\n",
    "    \"ror_org\",\n",
    "    \"ror_org_name\",\n",
    "    \"ror_org_link\",\n",
    "    \"ror_org_external_id\",\n",
    "    \"ror_org_location\",\n",
    "    \"ror_org_relationship\",\n",
    "    \"ror_org_domain\",\n",
    "]\n",
    "\n",
    "# counts\n",
    "with engine.connect() as conn:\n",
    "    rows = []\n",
    "    for t in TABLES:\n",
    "        cnt = conn.execute(text(f\"SELECT COUNT(*) FROM {t}\")).scalar_one()\n",
    "        rows.append({\"table\": t, \"rows\": cnt})\n",
    "    overview = pd.DataFrame(rows).sort_values(\"rows\", ascending=False)\n",
    "\n",
    "display(overview)\n",
    "\n",
    "# samples\n",
    "with engine.connect() as conn:\n",
    "    for t in TABLES:\n",
    "        print(f\"\\nðŸ”¹ Sample from {t}:\")\n",
    "        try:\n",
    "            df = pd.read_sql_query(text(f\"SELECT * FROM {t} LIMIT 5\"), conn)\n",
    "            display(df)\n",
    "        except Exception as e:\n",
    "            print(f\"(could not fetch sample: {e})\")\n",
    "\n",
    "# quick vector sanity checks\n",
    "with engine.connect() as conn:\n",
    "    print(\"\\nâœ… Vectors present:\")\n",
    "    display(pd.read_sql_query(\n",
    "        text(\"SELECT COUNT(*) AS with_vectors FROM ror_org WHERE embedding IS NOT NULL\"),\n",
    "        conn,\n",
    "    ))\n",
    "    print(\"\\nTop countries:\")\n",
    "    display(pd.read_sql_query(\n",
    "        text(\"SELECT country_code, COUNT(*) AS n FROM ror_org GROUP BY country_code ORDER BY n DESC LIMIT 10\"),\n",
    "        conn,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5f72a",
   "metadata": {},
   "source": [
    "## 7) Embed index_text and store vectors (with progress bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6078ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# Apple Silicon friendly defaults\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "os.environ.setdefault(\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\", \"0.0\")\n",
    "\n",
    "# Tune once\n",
    "BATCH = 16  # try 8â€“16 on Apple M-series\n",
    "UPDATE_SQL = \"UPDATE ror_org SET search_text = %s, embedding = %s WHERE ror_id = %s\"\n",
    "\n",
    "def embed_batch(texts):\n",
    "    \"\"\"Embed a small batch with the inner progress bar disabled.\"\"\"\n",
    "    # Uses _model from setup; ensures same prefix logic as your embed_texts()\n",
    "    tagged = [\"passage: \" + (t or \"\") for t in texts]\n",
    "    vecs = _model.encode(\n",
    "        tagged,\n",
    "        batch_size=BATCH,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False,  # <- no 'Batches:' lines\n",
    "    )\n",
    "    return vecs\n",
    "\n",
    "with psycopg.connect(DSN) as conn:  # one transaction\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SET LOCAL work_mem = '256MB';\")\n",
    "        print(\"Building pending setâ€¦\", flush=True)\n",
    "        cur.execute(\"\"\"\n",
    "            DROP TABLE IF EXISTS tmp_ror_pending;\n",
    "            CREATE TEMP TABLE tmp_ror_pending ON COMMIT DROP AS\n",
    "            SELECT o.ror_id, v.index_text\n",
    "            FROM ror_org o\n",
    "            JOIN ror_org_index_text_full v USING (ror_id)\n",
    "            WHERE o.embedding IS NULL OR o.search_text IS DISTINCT FROM v.index_text;\n",
    "            ANALYZE tmp_ror_pending;\n",
    "        \"\"\")\n",
    "        cur.execute(\"SELECT COUNT(*) FROM tmp_ror_pending;\")\n",
    "        total = cur.fetchone()[0]\n",
    "        print(f\"To (re)embed: {total:,}\", flush=True)\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"Nothing to update.\")\n",
    "    else:\n",
    "        # quick warm-up so first batch doesn't feel frozen\n",
    "        _ = _model.encode([\"passage: warmup\"], batch_size=1, normalize_embeddings=True, show_progress_bar=False)\n",
    "\n",
    "        # stream rows with a server-side cursor\n",
    "        with conn.cursor(name=\"embed_stream\") as scur:\n",
    "            scur.itersize = max(1000, BATCH)\n",
    "            scur.execute(\"SELECT ror_id, index_text FROM tmp_ror_pending ORDER BY ror_id;\")\n",
    "\n",
    "            pbar_embed = tqdm(total=total, desc=\"Embedding\", unit=\"org\")\n",
    "            pbar_write = tqdm(total=total, desc=\"Writing to Postgres\", unit=\"org\")\n",
    "\n",
    "            while True:\n",
    "                rows = scur.fetchmany(BATCH)\n",
    "                if not rows:\n",
    "                    break\n",
    "\n",
    "                rids  = [r[0] for r in rows]\n",
    "                texts = [r[1] or \"\" for r in rows]\n",
    "\n",
    "                vecs = embed_batch(texts)        # <- no inner bars\n",
    "                pbar_embed.update(len(rows))\n",
    "\n",
    "                with conn.cursor() as wcur:\n",
    "                    for rid, txt, v in zip(rids, texts, vecs):\n",
    "                        wcur.execute(UPDATE_SQL, (txt, v.tolist(), rid))\n",
    "                        pbar_write.update(1)\n",
    "\n",
    "            pbar_embed.close()\n",
    "            pbar_write.close()\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "print(\"âœ… Embedding pass completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed50eb",
   "metadata": {},
   "source": [
    "## 8) Ensure ANN indexes (IVFFLAT + optional HNSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cddc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "with psycopg.connect(DSN, autocommit=True) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS ror_org_embedding_ivfflat_idx\n",
    "            ON ror_org USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);\n",
    "            \"\"\"\n",
    "        )\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            DO $$\n",
    "            BEGIN\n",
    "              IF NOT EXISTS (SELECT 1 FROM pg_indexes WHERE indexname='ror_org_embedding_hnsw_idx') THEN\n",
    "                CREATE INDEX ror_org_embedding_hnsw_idx ON ror_org USING hnsw (embedding vector_cosine_ops);\n",
    "              END IF;\n",
    "            END $$;\n",
    "            \"\"\"\n",
    "        )\n",
    "print('Vector indexes ensured.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f6210",
   "metadata": {},
   "source": [
    "## 9) Search helper (cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_affiliations(qtext: str, k: int = 10):\n",
    "    qvec = embed_texts([qtext], is_passage=False)[0].tolist()\n",
    "    sql = (\n",
    "        \"SELECT ror_id, search_text, country_code, 1 - (embedding <=> %s) AS score \"\n",
    "        \"FROM ror_org WHERE embedding IS NOT NULL ORDER BY embedding <=> %s LIMIT %s;\"\n",
    "    )\n",
    "    with psycopg.connect(DSN) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(sql, (qvec, qvec, k))\n",
    "            return cur.fetchall()\n",
    "\n",
    "# Example usage (uncomment once embeddings exist):\n",
    "# for q in ['University of Groningen', 'Rijksuniversiteit Groningen', 'UniversitÃ© de GenÃ¨ve', 'ETH ZÃ¼rich']:\n",
    "#     print('\\nQuery:', q)\n",
    "#     for rid, txt, cc, score in search_affiliations(q, 5):\n",
    "#         print(f\"  {score:.4f}  {rid}  [{cc}]  {txt[:100]}â€¦\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
